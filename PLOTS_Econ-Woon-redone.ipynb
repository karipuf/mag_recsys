{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "field = \"Econ\"\n",
    "df2 = pd.read_csv(\"predictions_Econ.csv\") # Recommender system based\n",
    "df3 = pd.read_csv(\"distances_econ_filtered.csv\")\n",
    "\n",
    "if False: # Previously from reading from the full file - now use filtered version\n",
    "    #predictions include only authors with at least 15 venues, so remove from relevance authors not in predictions\n",
    "    df = pd.read_csv(\"distances_econ.csv\") # Relevance based\n",
    "    df3 = df[df.AID.isin(df2.AID)]\n",
    "    df3.to_csv(\"distances_econ_filtered.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rank_distances(df, aid):\n",
    "    df = df[df.index==aid].reset_index()\n",
    "    df = df.set_index('AID').T\n",
    "    df.columns = ['Values']\n",
    "    #v_list = df.sort_values(by=aid, ascending=False, axis=1)\n",
    "    v_list = df.sort_values(by='Values', ascending=False, axis=0)\n",
    "    venues = pd.DataFrame()\n",
    "    venues['VID'] =  list(v_list.index)\n",
    "    r_vals = v_list['Values'].values\n",
    "    \n",
    "    venues['Relevance'] = r_vals\n",
    "    #flip the values\n",
    "    venues['Relevance'] = 1/(1+venues['Relevance'])\n",
    "    #normalize\n",
    "    venues['Relevance'] = 100*venues['Relevance'] / venues['Relevance'].sum()\n",
    "    \n",
    "    venues = venues.head(n=200)\n",
    "    return venues\n",
    "\n",
    "def rank_citations(df, aid):\n",
    "    df = df[df.AID==aid]\n",
    "    df = df.sort_values(by='Citations')\n",
    "    \n",
    "    #normalize values\n",
    "    df['Citations'] = 100*df['Citations'] / df.Citations.sum()\n",
    "    \n",
    "    return df[['VID','Citations']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finding probabilistic versions\n",
    "\n",
    "if False:\n",
    "    Tau=.1\n",
    "    v2_distances=deepcopy(v_distances)\n",
    "    v2_citations=deepcopy(v_citations)\n",
    "\n",
    "    Rel=np.exp(v2_distances.Relevance/Tau)\n",
    "    v2_distances.Relevance=-np.log(Rel/Rel.sum())\n",
    "\n",
    "    Rel=np.exp(v2_citations.Citations/Tau)\n",
    "    v2_citations.Citations=-np.log(Rel/Rel.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Woon hack\n",
    "\n",
    "authors = list(df3.head(n=100)['AID'].values)\n",
    "\n",
    "df4 = df3.set_index(\"AID\") #Remove AID as column and set is as index\n",
    "df4 = df4[df2.VID.unique()] #Remove conferences not in prediction from distances\n",
    "\n",
    "#real_data = pd.read_csv(\"../data/\"+field+\"/\"+field+\"AIDPIDVIDANameVName.csv\")\n",
    "real_data = pd.read_csv(field+\"AIDPIDVIDANameVName.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Arrays were different lengths: 201800 vs 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-29de1e4db1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#rank_citations(df2,author)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrank_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f86874bc2d4a>\u001b[0m in \u001b[0;36mrank_citations\u001b[0;34m(df, aid)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrank_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAID\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0maid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Citations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wlwoon/anaconda2/envs/py3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/home/wlwoon/anaconda2/envs/py3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wlwoon/anaconda2/envs/py3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.vec_compare (pandas/_libs/lib.c:14288)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Arrays were different lengths: 201800 vs 100"
     ]
    }
   ],
   "source": [
    "#rank_citations(df2,author)\n",
    "rank_citations(df2,authors).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Woon hack\n",
    "authors = list(df3['AID'].values)\n",
    "def calc_R_C_woon(r, c, rp, cp, col,Tau=1):\n",
    "    r = r.merge(c, on=\"VID\", how=\"outer\") #to include all VIDs\n",
    "    r = r.fillna(0)\n",
    "    r[col] = r['Relevance']*rp + r['Citations']*cp\n",
    "    \n",
    "    Rel=np.exp(r[col]/Tau)\n",
    "    r[col]=-np.log(Rel/Rel.sum())\n",
    "    \n",
    "    return r[['VID',col]]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "#authors_=[authors[1]]\n",
    "cnt=0\n",
    "for author in authors:\n",
    "    \n",
    "    if cnt%100==0:\n",
    "        print cnt\n",
    "    cnt = cnt+1\n",
    "    \n",
    "    v_citations = rank_citations(df2,author)\n",
    "    \n",
    "    v_distances = rank_distances(df4,author)\n",
    "    v_distances.VID = np.random.permutation(v_distances.VID)\n",
    "    \n",
    "    v_real = real_data[real_data.AID==author]\n",
    "    \n",
    "    #calc the different combinations of recommendations for the author\n",
    "    temp = v_distances.merge(v_citations, on=\"VID\", how=\"outer\")\n",
    "    temp = temp.fillna(0)\n",
    "    temp = calc_R_C_woon(v_distances, v_citations, 1, 0, 'R100_C0')\n",
    "    temp2 = pd.DataFrame()\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.9, 0.1, 'R90_C10')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.8, 0.2, 'R80_C20')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.7, 0.3, 'R70_C30')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.6, 0.4, 'R60_C40')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.5, 0.5, 'R50_C50')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.4, 0.6, 'R40_C60')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.3, 0.7, 'R30_C70')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.2, 0.8, 'R20_C80')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0.1, 0.9, 'R10_C90')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    temp2 = calc_R_C_woon(v_distances, v_citations, 0, 1, 'R0_C100')\n",
    "    temp = temp.merge(temp2, on=\"VID\")\n",
    "    \n",
    "    #add the real results, T or F if author published in venue or not\n",
    "    temp['Real'] = temp.VID.isin(v_real.VID.values)\n",
    "    temp = temp[temp.Real] #extract rows of the author with venues used in real data\n",
    "    \n",
    "    #print temp\n",
    "    \n",
    "    #extract rows of venues in author's real data only\n",
    "    vc = v_real[['VID','AID']].groupby(\"VID\").count().reset_index().rename(columns={'AID':'VIDCount'})\n",
    "    temp = temp.merge(vc, on=\"VID\")\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    #calculate the similarity index (softmax) for each combination\n",
    "    tau = 1\n",
    "    \n",
    "    mixes = ['R100_C0','R90_C10','R80_C20', 'R70_C30', 'R60_C40', 'R50_C50', 'R40_C60', 'R30_C70', 'R20_C80', 'R10_C90', 'R0_C100']\n",
    "    \n",
    "    #for m in mixes:\n",
    "    #    temp['e_'+m] = np.exp(temp[m]/tau)\n",
    "    #    temp['sum_e_'+m] = temp['e_'+m]*temp['VIDCount']\n",
    "    #    temp['Sim_'+m] = -1*np.log(temp['e_'+m] / temp['sum_e_'+m].sum())\n",
    "    \n",
    "    #temp is the results of each individual author\n",
    "    #calc sim index by adding each column\n",
    "    #res = pd.DataFrame()\n",
    "    #res.set_value(0,'AID', author)\n",
    "    \n",
    "    res=pd.DataFrame([(temp[mixes]*np.tile(temp.VIDCount.values.reshape((-1,1)),(1,11))).sum()])/temp.VIDCount.sum()\n",
    "    res['AID']=author\n",
    "    #for m in mixes:\n",
    "    #    res['Sim_'+m] = temp['Sim_'+m].sum()\n",
    "    \n",
    "    results = results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R100_C0     200.459\n",
      "R90_C10     183.538\n",
      "R80_C20     178.133\n",
      "R70_C30     175.034\n",
      "R60_C40     173.833\n",
      "R50_C50     173.115\n",
      "R40_C60     173.444\n",
      "R30_C70      176.64\n",
      "R20_C80     183.763\n",
      "R10_C90     191.434\n",
      "R0_C100     200.459\n",
      "AID        85EBFEF8\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>average_similarity_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.402794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>0.438806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>0.458793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0.474186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0.486759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.497205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>0.505736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>0.512254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.516294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.515935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    relevance  average_similarity_index\n",
       "0         100                  0.402794\n",
       "1          90                  0.438806\n",
       "2          80                  0.458793\n",
       "3          70                  0.474186\n",
       "4          60                  0.486759\n",
       "5          50                  0.497205\n",
       "6          40                  0.505736\n",
       "7          30                  0.512254\n",
       "8          20                  0.516294\n",
       "9          10                  0.515935\n",
       "10          0                  0.499120"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mixes = ['R100_C0','R90_C10','R80_C20', 'R70_C30', 'R60_C40', 'R50_C50', 'R40_C60', 'R30_C70', 'R20_C80', 'R10_C90', 'R0_C100']\n",
    "\n",
    "max_sim = results[['R100_C0','R90_C10','R80_C20', 'R70_C30', 'R60_C40', 'R50_C50', 'R40_C60', 'R30_C70', 'R20_C80', 'R10_C90', 'R0_C100']].max().max()\n",
    "max_min = results[['R100_C0','R90_C10','R80_C20', 'R70_C30', 'R60_C40', 'R50_C50', 'R40_C60', 'R30_C70', 'R20_C80', 'R10_C90', 'R0_C100']].min().min()\n",
    "\n",
    "for m in mixes:\n",
    "    results['Norm_'+m] = results[m].apply(lambda x: (max_sim-x)/(max_sim-max_min))\n",
    "    \n",
    "plot = pd.DataFrame()\n",
    "plot['relevance'] = range(100,-1,-10)\n",
    "\n",
    "l = []\n",
    "for m in mixes:\n",
    "    l.append(results['Norm_'+m].mean())\n",
    "    \n",
    "plot['average_similarity_index'] = l\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(plot['relevance'], plot['average_similarity_index'])\n",
    "\n",
    "plt.xlabel('Relevance %')\n",
    "plt.ylabel('average similarity index')\n",
    "\n",
    "#plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"../data/images/rel_sim_tau\"+str(tau)+\"_temp.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
